{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the datasets and importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "path = glob.glob(\"*-house-disburse-detail.csv\")\n",
    "os.rename(\"2015Q2-house-disburse-detail-updated.csv\", \"2015Q2-house-disburse-detail.csv\")\n",
    "\n",
    "# General dictionary where all csv files will be read and stored in.\n",
    "\n",
    "data = {}\n",
    "    \n",
    "for eachUTF8 in path:\n",
    "    try:\n",
    "        d = pd.read_csv(eachUTF8, encoding=\"UTF-8\", thousands=\",\")    \n",
    "        data[eachUTF8] = d\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# The exception was added because two of the csv files had different encoding.\n",
    "# The following lines take care of this issue by using a different enconding in pd.read_csv and appending the output\n",
    "# to the general data dictionary where all cvs are read in.\n",
    "\n",
    "remaining_ds = [\"2018Q1-house-disburse-detail.csv\", \"2017Q2-house-disburse-detail.csv\"]\n",
    "data_remaining = {}\n",
    "\n",
    "for each8859 in remaining_ds:\n",
    "    d = pd.read_csv(each8859, encoding=\"iso-8859-1\", thousands=\",\")    \n",
    "    data[each8859] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that \"2015Q2 updated\" has been renamed directly in the folder for easier manipulation.\n",
    "\n",
    "df = pd.concat(data, sort=True)\n",
    "df[\"AMOUNT\"] = pd.to_numeric(df[\"AMOUNT\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading datasets per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Since the datasets were very large and it was causing trouble reading a complete dataset of all the years,\n",
    "# it was decided to divide each year into a dataset.\n",
    "\n",
    "read_2009 = ['2009Q3-house-disburse-detail.csv',\n",
    " '2009Q4-house-disburse-detail.csv']\n",
    "df_read_2009 = {}\n",
    "\n",
    "for each in read_2009:\n",
    "    d = pd.read_csv(each, encoding=\"UTF-8\", thousands=\",\")\n",
    "    df_read_2009[each] = d\n",
    "df_2009 = pd.concat(df_read_2009, sort=True)\n",
    "    \n",
    "read_2010 = ['2010Q1-house-disburse-detail.csv',\n",
    " '2010Q2-house-disburse-detail.csv',\n",
    " '2010Q3-house-disburse-detail.csv',\n",
    " '2010Q4-house-disburse-detail.csv']\n",
    "df_read_2010 = {}\n",
    "\n",
    "for each in read_2010:\n",
    "    d = pd.read_csv(each, encoding=\"UTF-8\", thousands=\",\")\n",
    "    df_read_2010[each] = d\n",
    "df_2010 = pd.concat(df_read_2010, sort=True)\n",
    "\n",
    "read_2011 = ['2011Q1-house-disburse-detail.csv',\n",
    " '2011Q2-house-disburse-detail.csv',\n",
    " '2011Q3-house-disburse-detail.csv',\n",
    " '2011Q4-house-disburse-detail.csv']\n",
    "df_read_2011 = {}\n",
    "\n",
    "for each in read_2011:\n",
    "    d = pd.read_csv(each, encoding=\"UTF-8\", thousands=\",\")\n",
    "    df_read_2011[each] = d\n",
    "df_2011 = pd.concat(df_read_2011, sort=True)\n",
    "\n",
    "read_2012 = ['2012Q1-house-disburse-detail.csv',\n",
    " '2012Q2-house-disburse-detail.csv',\n",
    " '2012Q3-house-disburse-detail.csv',\n",
    " '2012Q4-house-disburse-detail.csv']\n",
    "df_read_2012 = {}\n",
    "\n",
    "for each in read_2012:\n",
    "    d = pd.read_csv(each, encoding=\"UTF-8\", thousands=\",\")\n",
    "    df_read_2012[each] = d\n",
    "df_2012 = pd.concat(df_read_2012, sort=True)\n",
    "\n",
    "read_2013 = ['2013Q1-house-disburse-detail.csv',\n",
    " '2013Q2-house-disburse-detail.csv',\n",
    " '2013Q3-house-disburse-detail.csv',\n",
    " '2013Q4-house-disburse-detail.csv']\n",
    "df_read_2013 = {}\n",
    "\n",
    "for each in read_2013:\n",
    "    d = pd.read_csv(each, encoding=\"UTF-8\", thousands=\",\")\n",
    "    df_read_2013[each] = d\n",
    "df_2013 = pd.concat(df_read_2013, sort=True)\n",
    "\n",
    "read_2014 = ['2014Q1-house-disburse-detail.csv',\n",
    " '2014Q2-house-disburse-detail.csv',\n",
    " '2014Q3-house-disburse-detail.csv',\n",
    " '2014Q4-house-disburse-detail.csv']\n",
    "df_read_2014 = {}\n",
    "\n",
    "for each in read_2014:\n",
    "    d = pd.read_csv(each, encoding=\"UTF-8\", thousands=\",\")\n",
    "    df_read_2014[each] = d\n",
    "df_2014 = pd.concat(df_read_2014, sort=True)\n",
    "\n",
    "read_2015 = ['2015Q1-house-disburse-detail.csv',\n",
    " '2015Q2-house-disburse-detail.csv',\n",
    " '2015Q3-house-disburse-detail.csv',\n",
    " '2015Q4-house-disburse-detail.csv']\n",
    "df_read_2015 = {}\n",
    "\n",
    "for each in read_2015:\n",
    "    d = pd.read_csv(each, encoding=\"UTF-8\", thousands=\",\")\n",
    "    df_read_2015[each] = d\n",
    "df_2015 = pd.concat(df_read_2015, sort=True)\n",
    "\n",
    "read_2016 = ['2016Q1-house-disburse-detail.csv',\n",
    " '2016Q2-house-disburse-detail.csv',\n",
    " '2016Q3-house-disburse-detail.csv',\n",
    " '2016Q4-house-disburse-detail.csv']\n",
    "df_read_2016 = {}\n",
    "\n",
    "for each in read_2016:\n",
    "    d = pd.read_csv(each, encoding=\"UTF-8\", thousands=\",\")\n",
    "    df_read_2016[each] = d\n",
    "df_2016 = pd.concat(df_read_2016, sort=True)\n",
    "\n",
    "read_2017 = ['2017Q1-house-disburse-detail.csv',\n",
    " '2017Q2-house-disburse-detail.csv',\n",
    " '2017Q3-house-disburse-detail.csv',\n",
    " '2017Q4-house-disburse-detail.csv']\n",
    "df_read_2017 = {}\n",
    "\n",
    "for each in read_2017:\n",
    "    d = pd.read_csv(each, encoding=\"iso-8859-1\", thousands=\",\")\n",
    "    df_read_2017[each] = d\n",
    "df_2017 = pd.concat(df_read_2017, sort=True)\n",
    "\n",
    "read_2018 = ['2018Q1-house-disburse-detail.csv']\n",
    "df_read_2018 = {}\n",
    "\n",
    "for each in read_2018:\n",
    "    d = pd.read_csv(each, encoding=\"iso-8859-1\", thousands=\",\")\n",
    "    df_read_2018[each] = d\n",
    "df_2018 = pd.concat(df_read_2018, sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: \"What is the total of all the payments in the dataset?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = [df_2009, df_2010, df_2011, df_2012, df_2013, df_2014, df_2015, df_2016, df_2017, df_2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017[\"AMOUNT\"] = pd.to_numeric(df_2017[\"AMOUNT\"], errors=\"coerce\")\n",
    "total_payments = df_2009[\"AMOUNT\"].sum() + df_2010[\"AMOUNT\"].sum() + df_2011[\"AMOUNT\"].sum() + df_2012[\"AMOUNT\"].sum() + df_2013[\"AMOUNT\"].sum() + df_2014[\"AMOUNT\"].sum() + df_2015[\"AMOUNT\"].sum() + df_2016[\"AMOUNT\"].sum() + df_2017[\"AMOUNT\"].sum() + df_2018[\"AMOUNT\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For easier visualization of results, and organization, all the challenge's answers are being stored in this dict:\n",
    "\n",
    "results = {}\n",
    "\n",
    "results[\"1 - Total payments\"] = \"$\" + str(round(total_payments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: \"What was the average annual expenditure with a 'START DATE' date between January 1, 2010 and December 31, 2016 (inclusive)?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As some values are missing in the last csv files from 2017Q2 and 2018Q1, the following list was created for easier\n",
    "# and faster manipulation of data.\n",
    "\n",
    "quarters = [\n",
    "    \"2009Q3\", \"2009Q4\", \"2010Q1\", \"2010Q2\", \"2010Q3\", \"2010Q4\", \"2011Q1\", \"2011Q2\", \"2011Q3\", \"2011Q4\",\"2012Q1\",\n",
    "    \"2012Q2\", \"2012Q3\", \"2012Q4\", \"2013Q1\", \"2013Q2\", \"2013Q3\", \"2013Q4\", \"2014Q1\", \"2014Q2\", \"2014Q3\", \"2014Q4\",\n",
    "    \"2015Q1\", \"2015Q2\", \"2015Q3\", \"2015Q4\", \"2016Q1\", \"2016Q2\", \"2016Q3\", \"2016Q4\"]\n",
    "\n",
    "data_upto2016 = [each + \"-house-disburse-detail.csv\" for each in quarters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_upto2016 = {}\n",
    "\n",
    "for each in data_upto2016:\n",
    "    d = pd.read_csv(each, thousands=\",\")\n",
    "    df_upto2016[each] = d \n",
    "    \n",
    "df_upto2016 = pd.concat(df_upto2016, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to work with dates we had to call the very useful pd.to_datetime module.\n",
    "\n",
    "df_upto2016[\"START DATE\"] = pd.to_datetime(df_upto2016[\"START DATE\"], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AMOUNT                  float64\n",
       "BIOGUIDE_ID              object\n",
       "CATEGORY                 object\n",
       "DATE                     object\n",
       "END DATE                 object\n",
       "OFFICE                   object\n",
       "PAYEE                    object\n",
       "PROGRAM                  object\n",
       "PURPOSE                  object\n",
       "QUARTER                  object\n",
       "RECIP (orig.)            object\n",
       "RECORDID                 object\n",
       "START DATE       datetime64[ns]\n",
       "TRANSCODE                object\n",
       "TRANSCODELONG            object\n",
       "YEAR                     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upto2016.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2010Q1-house-disburse-detail.csv  25169    2010-01-01\n",
       "                                  29129    2010-01-01\n",
       "                                  61903    2010-01-01\n",
       "                                  125859   2010-01-01\n",
       "                                  61878    2010-01-01\n",
       "                                  61877    2010-01-01\n",
       "                                  61876    2010-01-01\n",
       "                                  61875    2010-01-01\n",
       "                                  91434    2010-01-01\n",
       "                                  91435    2010-01-01\n",
       "                                  91436    2010-01-01\n",
       "                                  61905    2010-01-01\n",
       "                                  125858   2010-01-01\n",
       "                                  125856   2010-01-01\n",
       "                                  91445    2010-01-01\n",
       "                                  91446    2010-01-01\n",
       "                                  29062    2010-01-01\n",
       "                                  29027    2010-01-01\n",
       "                                  28995    2010-01-01\n",
       "                                  28994    2010-01-01\n",
       "                                  28993    2010-01-01\n",
       "                                  28992    2010-01-01\n",
       "                                  28991    2010-01-01\n",
       "                                  125857   2010-01-01\n",
       "                                  125860   2010-01-01\n",
       "                                  125861   2010-01-01\n",
       "                                  125862   2010-01-01\n",
       "                                  91391    2010-01-01\n",
       "                                  125873   2010-01-01\n",
       "                                  29162    2010-01-01\n",
       "                                              ...    \n",
       "2016Q4-house-disburse-detail.csv  48080    2016-12-31\n",
       "                                  9232     2016-12-31\n",
       "                                  12427    2016-12-31\n",
       "                                  79009    2016-12-31\n",
       "                                  79007    2016-12-31\n",
       "                                  64119    2016-12-31\n",
       "                                  68597    2016-12-31\n",
       "2016Q3-house-disburse-detail.csv  81869    2016-12-31\n",
       "2016Q4-house-disburse-detail.csv  80552    2016-12-31\n",
       "                                  22045    2016-12-31\n",
       "                                  33515    2016-12-31\n",
       "                                  66250    2016-12-31\n",
       "                                  13940    2016-12-31\n",
       "                                  78550    2016-12-31\n",
       "                                  78559    2016-12-31\n",
       "2016Q3-house-disburse-detail.csv  81421    2016-12-31\n",
       "2016Q4-house-disburse-detail.csv  13945    2016-12-31\n",
       "                                  77760    2016-12-31\n",
       "                                  22053    2016-12-31\n",
       "                                  77752    2016-12-31\n",
       "                                  30587    2016-12-31\n",
       "                                  19548    2016-12-31\n",
       "2016Q3-house-disburse-detail.csv  81426    2016-12-31\n",
       "2016Q4-house-disburse-detail.csv  39895    2016-12-31\n",
       "                                  75869    2016-12-31\n",
       "                                  12833    2016-12-31\n",
       "                                  39569    2016-12-31\n",
       "                                  48995    2016-12-31\n",
       "                                  68978    2016-12-31\n",
       "                                  11460    2016-12-31\n",
       "Name: START DATE, Length: 2690189, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will filter all the dates from 01/01/2010 (inclusive) until 31/12/2016 (inclusive), \n",
    "# and all the positive payments.\n",
    "\n",
    "df_upto2016 = df_upto2016[\n",
    "    (df_upto2016[\"START DATE\"] > \"31/12/09\") &\n",
    "    (df_upto2016[\"START DATE\"] < \"01/01/2017\") &\n",
    "    (df_upto2016[\"AMOUNT\"] > 0)]\n",
    "\n",
    "df_upto2016[\"START DATE\"].sort_values()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_years = 7\n",
    "avg_annual_expenditure = round((np.sum(df_upto2016[\"AMOUNT\"]) / number_years))\n",
    "results[\"2 - Avg Annual Expenditure between 2010 and 2016\"] = \"$\" + str(avg_annual_expenditure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: \"What was the highest average staff salary among all representatives in 2016? Assume staff sizes is equal to the number of unique payees in the 'PERSONNEL COMPENSATION' category for each representative.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = df_upto2016[(df_upto2016[\"QUARTER\"] >= \"2016Q1\") & (df_upto2016[\"CATEGORY\"] == \"PERSONNEL COMPENSATION\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2016Q1', '2016Q2', '2016Q3', '2016Q4'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016[\"QUARTER\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PERSONNEL COMPENSATION'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016[\"CATEGORY\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016.groupby([\"BIOGUIDE_ID\"]).mean().sort_values([\"AMOUNT\"], ascending=False)\n",
    "\n",
    "results[\"3 - Highest average staff salary among all representatives in 2016\"] = \"$14243.39710\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - What percentage of the expenditures of the top 20 spenders in 2016 come from members of the Democratic Party? Representatives are identified by their 'BIOGUIDE_ID', which can be used to look up representatives with ProPublica's Congress API to find their party affiliation. Consider an expenditure as being in 2016 if its 'START DATE' is in 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BIOGUIDE_ID</th>\n",
       "      <th>AMOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K000376</td>\n",
       "      <td>2416608.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P000596</td>\n",
       "      <td>1617250.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C001103</td>\n",
       "      <td>1541817.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M000087</td>\n",
       "      <td>1372736.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N000002</td>\n",
       "      <td>1330448.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L000582</td>\n",
       "      <td>1330317.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P000611</td>\n",
       "      <td>1327903.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Z000018</td>\n",
       "      <td>1325314.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Y000033</td>\n",
       "      <td>1320239.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B001278</td>\n",
       "      <td>1318977.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>J000296</td>\n",
       "      <td>1315701.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>M001197</td>\n",
       "      <td>1308818.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>D000621</td>\n",
       "      <td>1308481.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M000404</td>\n",
       "      <td>1305631.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>R000588</td>\n",
       "      <td>1305190.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S001150</td>\n",
       "      <td>1301582.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Y000066</td>\n",
       "      <td>1299324.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C001049</td>\n",
       "      <td>1298375.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>L000579</td>\n",
       "      <td>1294600.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>T000460</td>\n",
       "      <td>1293250.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>L000578</td>\n",
       "      <td>1292976.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>D000610</td>\n",
       "      <td>1292819.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>P000606</td>\n",
       "      <td>1290866.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>W000822</td>\n",
       "      <td>1290247.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>M001160</td>\n",
       "      <td>1286958.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>D000191</td>\n",
       "      <td>1286487.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>G000577</td>\n",
       "      <td>1286474.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>C000714</td>\n",
       "      <td>1286409.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>P000197</td>\n",
       "      <td>1286311.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>N000184</td>\n",
       "      <td>1285424.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>S001187</td>\n",
       "      <td>1066107.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>L000567</td>\n",
       "      <td>1061837.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>H001063</td>\n",
       "      <td>1061435.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>B001292</td>\n",
       "      <td>1058298.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>R000593</td>\n",
       "      <td>1055984.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>F000372</td>\n",
       "      <td>1054074.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>J000289</td>\n",
       "      <td>1053752.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>R000570</td>\n",
       "      <td>1053719.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>C000266</td>\n",
       "      <td>1041272.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>C001078</td>\n",
       "      <td>1041094.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>G000563</td>\n",
       "      <td>1037529.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>J000255</td>\n",
       "      <td>1034500.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>M001150</td>\n",
       "      <td>1032033.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>Y000065</td>\n",
       "      <td>1030007.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>M001158</td>\n",
       "      <td>1028617.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>T000473</td>\n",
       "      <td>1024438.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>G000575</td>\n",
       "      <td>1010422.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>T000462</td>\n",
       "      <td>1001870.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>P000609</td>\n",
       "      <td>973515.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>F000043</td>\n",
       "      <td>971948.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>F000458</td>\n",
       "      <td>967519.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>B001290</td>\n",
       "      <td>921076.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>C001051</td>\n",
       "      <td>854262.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>W000806</td>\n",
       "      <td>802967.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>D000626</td>\n",
       "      <td>550058.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>C001108</td>\n",
       "      <td>90865.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>H001050</td>\n",
       "      <td>73224.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>E000296</td>\n",
       "      <td>49844.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>B000589</td>\n",
       "      <td>5398.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>G000569</td>\n",
       "      <td>3250.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>445 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    BIOGUIDE_ID      AMOUNT\n",
       "0       K000376  2416608.00\n",
       "1       P000596  1617250.49\n",
       "2       C001103  1541817.62\n",
       "3       M000087  1372736.72\n",
       "4       N000002  1330448.42\n",
       "5       L000582  1330317.69\n",
       "6       P000611  1327903.27\n",
       "7       Z000018  1325314.38\n",
       "8       Y000033  1320239.12\n",
       "9       B001278  1318977.90\n",
       "10      J000296  1315701.20\n",
       "11      M001197  1308818.29\n",
       "12      D000621  1308481.90\n",
       "13      M000404  1305631.91\n",
       "14      R000588  1305190.33\n",
       "15      S001150  1301582.11\n",
       "16      Y000066  1299324.79\n",
       "17      C001049  1298375.10\n",
       "18      L000579  1294600.07\n",
       "19      T000460  1293250.27\n",
       "20      L000578  1292976.05\n",
       "21      D000610  1292819.19\n",
       "22      P000606  1290866.57\n",
       "23      W000822  1290247.91\n",
       "24      M001160  1286958.61\n",
       "25      D000191  1286487.19\n",
       "26      G000577  1286474.17\n",
       "27      C000714  1286409.47\n",
       "28      P000197  1286311.29\n",
       "29      N000184  1285424.66\n",
       "..          ...         ...\n",
       "415     S001187  1066107.20\n",
       "416     L000567  1061837.87\n",
       "417     H001063  1061435.98\n",
       "418     B001292  1058298.67\n",
       "419     R000593  1055984.10\n",
       "420     F000372  1054074.10\n",
       "421     J000289  1053752.41\n",
       "422     R000570  1053719.34\n",
       "423     C000266  1041272.75\n",
       "424     C001078  1041094.69\n",
       "425     G000563  1037529.09\n",
       "426     J000255  1034500.86\n",
       "427     M001150  1032033.46\n",
       "428     Y000065  1030007.59\n",
       "429     M001158  1028617.48\n",
       "430     T000473  1024438.52\n",
       "431     G000575  1010422.39\n",
       "432     T000462  1001870.88\n",
       "433     P000609   973515.37\n",
       "434     F000043   971948.94\n",
       "435     F000458   967519.12\n",
       "436     B001290   921076.38\n",
       "437     C001051   854262.87\n",
       "438     W000806   802967.00\n",
       "439     D000626   550058.24\n",
       "440     C001108    90865.30\n",
       "441     H001050    73224.85\n",
       "442     E000296    49844.99\n",
       "443     B000589     5398.12\n",
       "444     G000569     3250.00\n",
       "\n",
       "[445 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The total number of members was grouped by its total expenditure in 2016\n",
    "\n",
    "df_party_affiliation = df_upto2016[(df_upto2016[\"START DATE\"] >= \"01/01/2016\") & (df_upto2016[\"START DATE\"] <= \"31/12/2016\")]\n",
    "df_party_affiliation.dropna(subset=[\"BIOGUIDE_ID\"], inplace=True)\n",
    "df_party_affiliation = df_party_affiliation.groupby([\"BIOGUIDE_ID\"])[\"AMOUNT\"].sum()\n",
    "\n",
    "df_party_affiliation = pd.DataFrame(df_party_affiliation)\n",
    "df_party_affiliation = df_party_affiliation.sort_values(\"AMOUNT\", ascending=False)\n",
    "df_party_affiliation.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After sorting the representatives by the amount spent in 2016, the total lenght of the list is checked and a the top\n",
    "# 20% is added to a new list which will be used to request information from the Propublica Congress API.\n",
    "\n",
    "members_top20percent = df_party_affiliation[0:89]\n",
    "members_top20percent = members_top20percent.drop(\"AMOUNT\", axis=1)\n",
    "members_top20percent = members_top20percent.reset_index()\n",
    "members_top20percent = members_top20percent[\"BIOGUIDE_ID\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "party_affiliation = {}\n",
    "\n",
    "\n",
    "url = \"https://api.propublica.org/congress/v1/members/\"\n",
    "headers = {\"X-API-Key\" : \"k0zGCYYDooXfXPMKhw628lqDbRtZiFZ6ysnnExLU\"}\n",
    "\n",
    "def get_account_info():\n",
    "    for each in members_top20percent:\n",
    "        api_url = '{0}'.format(url) + str(each) + \".json\".format(url)\n",
    "        response = requests.get(api_url, headers=headers)\n",
    "\n",
    "        for i in response.json()['results']:\n",
    "            for g in i['roles']:\n",
    "                for j in g['party']:\n",
    "                    if g[\"party\"] == \"D\":\n",
    "                        party_affiliation[each] = \"D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_account_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P000596': 'D',\n",
       " 'M000087': 'D',\n",
       " 'N000002': 'D',\n",
       " 'L000582': 'D',\n",
       " 'B001278': 'D',\n",
       " 'M000404': 'D',\n",
       " 'R000588': 'D',\n",
       " 'S001150': 'D',\n",
       " 'C001049': 'D',\n",
       " 'L000579': 'D',\n",
       " 'T000460': 'D',\n",
       " 'D000610': 'D',\n",
       " 'W000822': 'D',\n",
       " 'M001160': 'D',\n",
       " 'D000191': 'D',\n",
       " 'C000714': 'D',\n",
       " 'P000197': 'D',\n",
       " 'W000797': 'D',\n",
       " 'L000562': 'D',\n",
       " 'K000368': 'D',\n",
       " 'D000598': 'D',\n",
       " 'M001166': 'D',\n",
       " 'M001163': 'D',\n",
       " 'M001185': 'D',\n",
       " 'C001036': 'D',\n",
       " 'M001191': 'D',\n",
       " 'L000287': 'D',\n",
       " 'C001072': 'D',\n",
       " 'S001145': 'D',\n",
       " 'L000551': 'D',\n",
       " 'B000574': 'D',\n",
       " 'H001038': 'D',\n",
       " 'H001064': 'D',\n",
       " 'S000510': 'D',\n",
       " 'T000465': 'D',\n",
       " 'G000559': 'D',\n",
       " 'H001034': 'D',\n",
       " 'N000127': 'D',\n",
       " 'F000030': 'D',\n",
       " 'H001068': 'D',\n",
       " 'D000216': 'D',\n",
       " 'P000593': 'D',\n",
       " 'G000574': 'D',\n",
       " 'D000197': 'D'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "party_affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_top_spending_democrats = round(((len(party_affiliation) / len(members_top20percent))*100), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"4 - What percentage of the expenditures of the top 20 spenders in 2016 come from members of the Democratic Party?\"] = str(percentage_top_spending_democrats) + \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5: Define the 'COVERAGE PERIOD' for each payment as the difference (in days) between 'END DATE' and 'START DATE'. What is the standard deviation in 'COVERAGE PERIOD'? Only consider payments with strictly positive amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coverage = df[(df[\"END DATE\"].notnull()) & (df[\"START DATE\"].notnull()) & (df[\"AMOUNT\"] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_coverage = df_coverage[[\"END DATE\", \"START DATE\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_coverage[\"END DATE\"] = pd.to_datetime(df_new_coverage[\"END DATE\"], infer_datetime_format=True, errors=\"coerce\")\n",
    "df_new_coverage[\"START DATE\"] = pd.to_datetime(df_new_coverage[\"START DATE\"], infer_datetime_format=True, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_coverage[\"COVERAGE PERIOD\"] = df_new_coverage[\"END DATE\"] - df_new_coverage[\"START DATE\"]\n",
    "df_new_coverage = df_new_coverage[df_new_coverage[\"COVERAGE PERIOD\"] > pd.Timedelta(0)]\n",
    "df_new_coverage[\"COVERAGE PERIOD\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"5 - Define the COVERAGE PERIOD\"] = \"std = 67 days\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Find the 'OFFICE' with the highest total expenditures with a 'START DATE' in 2016. For this office, find the 'PURPOSE' that accounts for the highest total expenditures. What fraction of the total expenditures (all records, all offices) with a 'START DATE' in 2016 do these expenditures amount to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016_office = df_upto2016[(df_upto2016[\"START DATE\"] >= \"01/01/2016\")]\n",
    "df_2016_office = df_2016_office.groupby([\"OFFICE\"]).max()\n",
    "df_2016_office = df_2016_office.sort_values(by=['AMOUNT'], ascending=False)\n",
    "\n",
    "total_spend_all_offices = df_2016_office[\"AMOUNT\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016_top_office = df_upto2016[(df_upto2016[\"START DATE\"] >= \"01/01/2016\") & (df_upto2016[\"OFFICE\"] == \"GOVERNMENT CONTRIBUTIONS\")]\n",
    "df_2016_top_office = df_2016_top_office.sort_values(by=['PURPOSE'], ascending=False)\n",
    "df_2016_top_office = df_2016_top_office.groupby([\"PURPOSE\"]).max()\n",
    "df_2016_top_office = df_2016_top_office.sort_values(by=['AMOUNT'], ascending=False)\n",
    "df_2016_top_office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FERS_expenditure = 7556076.77\n",
    "percentage_expenditure = (FERS_expenditure / total_spend_all_offices)*100\n",
    "percentage_expenditure = round(percentage_expenditure, 1)\n",
    "percentage_expenditure\n",
    "results[\"6 - Top spending office\"] = \"The office with the highest spend is GOVERNMENT CONTRIBUTIONS. The purpose of expense is FERS, and it accounts for a \" + str(percentage_expenditure) + \"% of the total expenditure of all offices in 2016.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - What was the median rate of annual turnover in staff between 2011 and 2016 (inclusive)? Turnover for 2011 should be calculated as the fraction of a representative's staff from 2010 who did not carry over to 2011. Only consider representatives who served for at least 4 years and had staff size of at least 5 every year that they served."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2010_2016 = df_upto2016[(df_upto2016[\"QUARTER\"] >= \"2010Q1\") & (df_upto2016[\"QUARTER\"] <= \"2016Q4\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're keeping only entries where we can identify the Representative\n",
    "\n",
    "df_2010_2016.dropna(subset=[\"BIOGUIDE_ID\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_turnover_staff_size = pd.concat([df_2010_2016[\"BIOGUIDE_ID\"], df_2010_2016[\"PAYEE\"], df_2010_2016[\"QUARTER\"], df_2010_2016[\"YEAR\"]], axis=1)\n",
    "df_turnover_staff_size[\"YEAR\"] = df_turnover_staff_size[\"YEAR\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_quarters = 16\n",
    "# 16 quarters = 4 years\n",
    "threshold_payees = 5\n",
    "\n",
    "# After creating a cleaned list ready for analysis, the transform() function was used to filter the list by a minimum of \n",
    "# 4 years and minimum staff of 5.\n",
    "\n",
    "df_turnover_staff_size = df_turnover_staff_size[df_turnover_staff_size.groupby([\"BIOGUIDE_ID\"])[\"QUARTER\"].transform(\"nunique\") > threshold_quarters]\n",
    "df_turnover_staff_size = df_turnover_staff_size[df_turnover_staff_size.groupby([\"BIOGUIDE_ID\", \"YEAR\"])[\"PAYEE\"].transform(\"nunique\") >= threshold_payees]\n",
    "df_turnover_staff_size = df_turnover_staff_size.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to some discrepancies between the year stated in the QUARTER and YEAR columns, a filter to excluded year < 2009\n",
    "# was applied in order to minimize error.\n",
    "\n",
    "df_turnover_staff_size = df_turnover_staff_size[df_turnover_staff_size[\"YEAR\"] > 2008]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_turnover_staff_size = df_turnover_staff_size.groupby([\"BIOGUIDE_ID\", \"YEAR\"])[\"PAYEE\"].nunique().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_turnover_staff_size.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate the turnover, a subtraction of df_turnover_staff_size[\"PAYEE\"] - df_turnover_staff_size[\"PAYEE\" - 1]\n",
    "# had to be performed. The problem was that after every last year, for the unique \"BIOGUIDE_ID\" values, the subtraction\n",
    "# would mix the first year of one representative with the last year of the previous representative in the list.\n",
    "# A solution to this issue was to create another dataframe that added a NaN row before and after each unique value in \n",
    "# df_turnover_staff_size[\"BIOGUIDE_ID\"]. This way the calculation could be accurately performed without \n",
    "# mixing representatives' data with each other.\n",
    "\n",
    "shifted_df = df_turnover_staff_size.shift(1)\n",
    "df_turnover_staff_size[\"TURNOVER\"]=(\n",
    "    pd.Series(\n",
    "        np.where(\n",
    "            df_turnover_staff_size[\"BIOGUIDE_ID\"]==shifted_df[\"BIOGUIDE_ID\"],\n",
    "            df_turnover_staff_size[\"PAYEE\"]-shifted_df[\"PAYEE\"],\n",
    "            np.NaN\n",
    "        )\n",
    "    )\n",
    ").shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_turnover = round(np.mean(df_turnover_staff_size[\"TURNOVER\"]), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"7 - What was the median rate of annual turnover in staff between 2011 and 2016 (inclusive)?\"] = str(round(mean_turnover, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
